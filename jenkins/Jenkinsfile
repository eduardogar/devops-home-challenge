pipeline {

    agent any

    // Define environment variables that are available to all stages.
    environment {
        REPO_URL           = 'https://github.com/eduardogar/devops-home-challenge.git'
        BRANCH_NAME        = 'main'
        REGISTRY_URL       = 'host.docker.internal:5000'
        APP_NAME           = 'devops-challenge-app'
        DOCKER_IMAGE_VERSIONED = "${REGISTRY_URL}/${APP_NAME}:${env.BUILD_NUMBER}"
        DOCKER_IMAGE_LATEST    = "${REGISTRY_URL}/${APP_NAME}:latest"
        DOCKER_IMAGE_STABLE    = "${REGISTRY_URL}/${APP_NAME}:stable"
    }

    stages {
        // Stage 1: Checkout the source code from the repository.
        stage('Code Checkout') {
            steps {

                cleanWs()

                git url: "${REPO_URL}", branch: "${BRANCH_NAME}"
            }
        }

        // Stage 2: Perform a security scan on the Infrastructure as Code (IaC) files using tfsec.
        stage('IaC Security Scan') {
            steps {
                sh 'tfsec ./terraform'
            }
        }

        // Stage 2.5 Ensure Docker network and API relay exist 
        stage('Docker Network & API Relay') {
            steps {
                sh """
                set -e

                # Create network (no-op if it already exists)
                docker network create devops-net || true

                # Attach containers (no-op if already attached)
                docker network connect devops-net jenkins || true
                docker network connect devops-net local-registry || true
                docker network connect devops-net devops-challenge || true

                # Recreate API relay that exposes 0.0.0.0:8443 -> 127.0.0.1:8443 in the minikube node
                docker rm -f k8s-apiserver-relay 2>/dev/null || true
                docker run -d --name k8s-apiserver-relay --restart unless-stopped \\
                  --network container:devops-challenge alpine/socat \\
                  TCP-LISTEN:8443,fork,reuseaddr TCP:127.0.0.1:8443

                # Quick reachability probe (prints NOT reachable if fails)
                bash -lc 'getent hosts devops-challenge; (echo > /dev/tcp/devops-challenge/8443) >/dev/null 2>&1 && echo "API :8443 reachable" || echo "API :8443 NOT reachable"'
                """
            }
        }

        // Stage 3: Configure the Kubernetes Context.
        stage('Configure Kubernetes Context') {
            steps{
                sh """
                # Set KUBECONFIG to a new file in the workspace
                export KUBECONFIG=${WORKSPACE}/kubeconfig

                # Generate kubeconfig that points to the Minikube node and embeds client certs/keys
                cat > ${WORKSPACE}/kubeconfig << EOF
apiVersion: v1
clusters:
- cluster:
    server: https://devops-challenge:8443
    insecure-skip-tls-verify: true
  name: devops-challenge
contexts:
- context:
    cluster: devops-challenge
    namespace: default
    user: devops-challenge
  name: devops-challenge
current-context: devops-challenge
kind: Config
preferences: {}
users:
- name: devops-challenge
  user:
    client-certificate-data: \$(cat /var/jenkins_home/.minikube/profiles/devops-challenge/client.crt | base64 -w0)
    client-key-data: \$(cat /var/jenkins_home/.minikube/profiles/devops-challenge/client.key | base64 -w0)
EOF
                kubectl config use-context devops-challenge
                kubectl --kubeconfig "$WORKSPACE/kubeconfig" cluster-info
                kubectl --kubeconfig "$WORKSPACE/kubeconfig" get nodes

                kubectl get nodes

                # make sure namespaces exist (idempotent)
                kubectl create ns staging --dry-run=client -o yaml | kubectl apply -f -
                kubectl create ns production --dry-run=client -o yaml | kubectl apply -f -
                """
            }
        }

        // Stage 4: Build and tag the Docker image.
        stage('Docker Build & Tag') {
            steps {
                script {
                    echo "Building and tagging new image..."
                    sh "docker build --build-arg APP_VERSION=v1.${env.BUILD_NUMBER} -t ${DOCKER_IMAGE_VERSIONED} ./application"

                    echo "Updating 'stable' tag..."
                    try {
                        sh "docker pull ${DOCKER_IMAGE_LATEST}"
                        sh "docker tag ${DOCKER_IMAGE_LATEST} ${DOCKER_IMAGE_STABLE}"
                        sh "docker push ${DOCKER_IMAGE_STABLE}"
                    } catch (e) {
                        echo "Could not re-tag previous 'latest' to 'stable'. This is expected on the first run."
                    }

                    echo "Updating 'latest' tag..."
                    sh "docker tag ${DOCKER_IMAGE_VERSIONED} ${DOCKER_IMAGE_LATEST}"

                    echo "Pushing all new tags to the local Docker registry..."
                    sh "docker push ${DOCKER_IMAGE_VERSIONED}"
                    sh "docker push ${DOCKER_IMAGE_LATEST}"
                }
            }
        }

        // Stage 5: Scan the newly built Docker image for vulnerabilities using Trivy.
        stage('Image Security Scan') {
            steps {
                script {
                    echo "Scanning versioned image for vulnerabilities..."
                    sh "trivy image --exit-code 0 --severity HIGH,CRITICAL ${DOCKER_IMAGE_VERSIONED}"
                }
            }
        }

        // Stage 6: Syntax check.
        stage('Helm Lint/Template') {
            steps{
                sh """
                ls -l kubernetes/helm-chart/
                ls -l kubernetes/helm-chart/values.yaml
                cat kubernetes/helm-chart/values.yaml
                cat kubernetes/helm-chart/templates/service.yaml
                helm lint ./kubernetes/helm-chart
                helm template my-app-staging ./kubernetes/helm-chart \\
                -f kubernetes/helm-chart/values.yaml \\
                --set image.tag='test' --set replicaCount=1 \\
                --set config.welcomeMessage="Template Smoke Test"
                """
            }
        }

        // Stage 7: Deploy reverse proxy.
        stage('Ingress Controller as LoadBalancer') {
            steps {
                sh '''
                  set -euo 

                  # Verify controller exists 
                  if ! kubectl --kubeconfig "${WORKSPACE}/kubeconfig" -n ingress-nginx get deploy ingress-nginx-controller >/dev/null 2>&1; then
                    echo "ERROR: ingress-nginx controller not found. Enable it on the host:  minikube -p devops-challenge addons enable ingress"
                    exit 1
                  fi

                  # Apply LB patch 
                  kubectl --kubeconfig "${WORKSPACE}/kubeconfig" apply -f "kubernetes/ingress-nginx-lb.yaml"

                  # Wait for controller rollout
                  kubectl --kubeconfig "${WORKSPACE}/kubeconfig" -n ingress-nginx rollout status deploy/ingress-nginx-controller --timeout=120s || true

                  # Show the service (EXTERNAL-IP will be <pending> until `minikube tunnel` runs on the host)
                  kubectl --kubeconfig "${WORKSPACE}/kubeconfig" -n ingress-nginx get svc ingress-nginx-controller -o wide
                '''
            }
        }

        // Stage 8: Deploy to Staging.
        stage('Deploy to Staging') {
            steps {
                echo 'Deploying application to the staging namespace using Helm...'
                sh """
                    helm upgrade --install my-app-staging ./kubernetes/helm-chart \\
                      --namespace staging \\
                      --set image.repository=${REGISTRY_URL}/${APP_NAME} \\
                      --set image.tag=${env.BUILD_NUMBER} \\
                      --set replicaCount=1 \\
                      --set-string config.welcomeMessage="Welcome to the STAGING Environment!" \\
                      --set service.port=80 \\
                      --set service.targetPort=8000 \\
                      --set ingress.enabled=true \\
                      --set ingress.className=nginx \\
                      --set ingress.host=my-app-staging.local \\
                      --set ingress.path=/ \\
                      --set ingress.pathType=Prefix \\
                      --kubeconfig ${WORKSPACE}/kubeconfig
                """
            }
        }

        // Stage 8: Manual approval for promotion to production.
        stage('Approval for Production') {
            steps {
                input message: 'Deploy to Production?', ok: 'Yes'
            }
        }

        // Stage 9: Deploy the stable version of the application to the production environment.
        stage('Deploy to Production') {
            steps {
                echo 'Deploying application to the production namespace using Helm...'
                sh """
                    helm upgrade --install my-app-production ./kubernetes/helm-chart \\
                      --namespace production \\
                      --set image.repository=${REGISTRY_URL}/${APP_NAME} \\
                      --set image.tag=stable \\
                      --set replicaCount=3 \\
                      --set-string config.welcomeMessage="Welcome to the PRODUCTION Environment!" \\
                      --set service.port=80 \\
                      --set service.targetPort=8000 \\
                      --set ingress.enabled=true \\
                      --set ingress.className=nginx \\
                      --set ingress.host=my-app.local \\
                      --set ingress.path=/ \\
                      --set ingress.pathType=Prefix \\
                      --kubeconfig ${WORKSPACE}/kubeconfig
                """
            }
        }
    }

    post {

        always {
            echo "Cleaning up the workspace..."

            cleanWs()
        }
    }
}
